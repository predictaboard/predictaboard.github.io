<!DOCTYPE html>
<html>
<head>

    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="PredictaBoard promotes predictable AI systems.">
    <meta property="og:title" content="PredictaBoard: jointly benchmarking LLM Score and its Predictability"/>
    <meta property="og:description" content="PredictaBoard promotes predictable AI systems."/>
    <meta property="og:url" content="https://predictaboard.github.io/"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="https://predictaboard.github.io/static/images/Predict3b_two.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta property="twitter:title" content="PredictaBoard: Benchmarking LLM Score Predictability"/>
    <meta property="twitter:description" content="PredictaBoard promotes predictable AI systems."/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="https://predictaboard.github.io/static/images/Predict3b_two.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords"
          content="AI Evaluation, Large Language Models, LLMs, Large Language Models Evaluation, LLM Evaluation, AI Benchmarks, AI Assessment, AI Testing, AI Performance, Machine Learning Evaluation, Predictability, Evals, LLM Evals"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>PredictaBoard: Benchmarking LLM Score Predictability</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans" rel="stylesheet">

    <!-- jQuery first -->
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

    <!-- Bootstrap 4 CSS and JS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Bootstrap Select CSS and JS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.18/dist/css/bootstrap-select.min.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.18/dist/js/bootstrap-select.min.js"></script>

    <link rel="stylesheet" href="static/css/core.css">
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">
    <link rel="stylesheet" href="static/css/components.css">


    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/index.js"></script>
    <script src="static/js/leaderboardFilters.js"></script>

    <style>
        * {
            font-family: 'Google Sans', sans-serif !important;
        }

        @media screen and (max-width: 768px) {
            .publication-title {
                font-size: 1.8rem !important;
            }

            .publication-authors {
                font-size: 0.9rem !important;
            }

            .author-block {
                display: inline-block;
                margin-bottom: 0.5rem;
            }

            .link-block {
                display: inline-block;
                margin: 0.25rem;
            }

            .subtitle {
                font-size: 0.9rem !important;
            }

            .content p {
                font-size: 0.9rem;
            }

            img {
                width: 100% !important;
            }

            .container {
                padding: 1rem;
            }
        }
    </style>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">PredictaBoard: Benchmarking LLM Score Predictability</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
    <a href="http://www.lorenzopacchiardi.me/" target="_blank">Lorenzo Pacchiardi</a><sup>1</sup>,
  </span>
                        <span class="author-block">
    <a href="https://kv301.user.srcf.net/" target="_blank">Konstantinos Voudouris</a><sup>1,2</sup>,
  </span>
                        <span class="author-block">
    <a href="https://www.lcfi.ac.uk/people/ben-slater" target="_blank">Ben Slater</a><sup>1</sup>,
  </span>
                        <span class="author-block">
    <a href="https://nandomp.github.io/" target="_blank">Fernando Martínez-Plumed</a><sup>3</sup>,
  </span>
                        <span class="author-block">
    <a href="https://josephorallo.webs.upv.es/" target="_blank">José Hernández-Orallo</a><sup>1,3</sup>,
  </span>
                        <span class="author-block">
    <a href="https://lexzhou.github.io/" target="_blank">Lexin Zhou</a><sup>1,3</sup>,
  </span>
                        <span class="author-block">
    <a href="https://schellaert.org/" target="_blank">Wout Schellaert</a><sup>3</sup>
  </span>
                    </div>

                    <div class="is-size-5 publication-authors">
  <span class="author-block">
    <sup>1</sup>Leverhulme Centre for the Future of Intelligence, University of Cambridge, United Kingdom<br>
    <sup>2</sup>Institute for Human-Centered AI, Helmholtz Zentrum Munich, Germany<br>
    <sup>3</sup>VRAIN, Universitat Politècnica de València, Spain
  </span>
                        <!-- If any authors contributed equally, you can include the following:
                        <span class="eql-cntrb">
                          <small><br><sup>*</sup>Indicates Equal Contribution</small>
                        </span>
                        -->
                    </div>


                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                                    <a href="https://arxiv.org/abs/2502.14445" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                      <img src="static/images/arxiv-logomark-small.svg"
                                           style="width: 1em; height: 1em;">
                                    </span>
                                    <span>ArXiv</span>
                                  </a>
                                </span>

                            <span class="link-block">
                      <a href="https://arxiv.org/pdf/2502.14445" target="_blank"
                         class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                            <!-- Github link -->
                            <span class="link-block">
                                <a href="https://github.com/Kinds-of-Intelligence-CFI/PredictaBoard" target="_blank"
                                   class="external-link button is-normal is-rounded is-dark">
                                <span class="icon">
                                  <img src="static/images/github-mark-white.svg" width="24px" height="24px">
                                </span>
                                <span>Code</span>
                              </a>
                            </span>


                            <span class="link-block">
                              <a href="https://huggingface.co/collections/kvoudouris/predictaboard-67b6042ee09a99a3b0bbebd0"
                                 target="_blank"
                                 class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                <img src="static/images/huggingface_logo-noborder.svg" width="24px" height="24px">
                              </span>
                              <span>Dataset</span>
                            </a>
                          </span>

                            <!-- ArXiv abstract Link -->
                        </div>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <div style="text-align: center;">
                <img src="static/images/Predict3b.svg" alt="The PredictaBoard framework"
                     style="width: 80%;">
            </div>
            <h2 class="subtitle is-4 has-text-justified">
                We introduce PredictaBoard, a novel benchmarking framework that simultaneously evaluates an LLM’s score
                and its
                <i>predictability</i> on individual questions by an "assessor" module. This makes the
                size of the LLM’s <i>predictably valid</i> operating region the crucial consideration.
                Thus, PredictaBoard shifts the focus from average performance and promotes the
                development of AI systems that enable the anticipation of errors
                —an essential consideration for high-stakes scenarios.
            </h2>
        </div>
    </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Despite possessing impressive skills, Large Language Models (LLMs) often fail unpredictably,
                        demonstrating inconsistent success in even basic common sense reasoning tasks. This
                        unpredictability poses a significant challenge to ensuring their safe deployment, as identifying
                        and operating within a reliable "safe zone" is essential for mitigating risks. To address this,
                        we present <em>PredictaBoard</em>, a novel collaborative benchmarking framework designed to
                        evaluate the ability of score predictors (referred to as assessors) to anticipate LLM errors on
                        specific task instances (i.e., prompts) from existing datasets. PredictaBoard evaluates pairs of
                        LLMs and assessors by considering the rejection rate at different tolerance errors. As such,
                        PredictaBoard stimulates research into developing better assessors and making LLMs more
                        predictable, not only with a higher average performance. We conduct illustrative experiments
                        using baseline assessors and state-of-the-art LLMs. PredictaBoard highlights the critical need
                        to evaluate predictability alongside performance, paving the way for safer AI systems where
                        errors are not only minimised but also anticipated and effectively mitigated.</p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->

<!-- Similarity Metric -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h1 class="title is-3 has-text-centered">Predicting validity</h1>
            <div class="content has-text-justified">
                <div class="subtitle is-5">
                    We use <i>assessors</i> to predict the score (or, more generally, validity) of a model on a
                    question.
                    Assessors can be trained to predict model score from features of the question using a dataset of
                    (questions, scores).
                    We require assessors to make predictions without relying on the model's outputs to prevent them from
                    leveraging knowledge of the ground truth.
                    However, assessors can potentially use model internals.
                    Moreover, while we focus on assessors, PredictaBoard can be used to evaluate other approaches to
                    validity prediction,
                    such as self-confidence or guarantees.
                </div>

                <div style="text-align: center;">
                    <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 0px; margin-bottom: 0px;">
                        <img src="static/images/Assessors4.svg" alt="How an assessor is trained"
                             style="width: 40%;">
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero is-light">
    <div class="hero-body">
        <div class="container">
            <h1 class="title is-3 has-text-centered">Metrics for predictability</h1>
            <div class="content has-text-justified">
                <div class="subtitle is-6">
                    To jointly measure LLM score and predictability, we consider the Accuracy-Rejection Curve (ARC,
                    displayed below).
                    This is obtained by considering varying rejection thresholds for the assessor and plotting the LLM
                    accuracy
                    on the non-rejected samples as a function of the rejection rate corresponding to each threshold.
                    For a fixed error tolerance (e.g., 20%), we can then compute the highest non-rejection rate that
                    leads
                    to an error below the tolerance. We call this the Predictably Valid Region (PVR).
                    Moreover, to consider multiple rejection thresholds, we can compute the Area Under the ARC (AUARC)
                    curve.
                    <br><br>
                    PredictaBoard also includes other metrics that independently score the assessor or the LLM, but the
                    ARC
                    and its derived metrics allow understanding their combined behaviour.
                </div>

                <div style="text-align: center;">
                    <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 20px; margin-bottom: 5px;">
                        <img src="static/images/ARC_2systems_noSPPR.svg" alt="ARC curves"
                             style="width: 40%;">
                    </div>
                </div>
                <p style="margin-top: 1rem;">
                    In the plot above, each system corresponds to a LLM-assessor pair.
                    Systems A and B have overall accuracy a and b respectively, with b larger than A. However, for an
                    error tolerance of 20%,
                    System A has a larger non-rejection rate. We say therefore that System A's 0.8 PVR is larger than
                    System B's
                    (where 0.8 refers to the minimum required accuracy).
                </p>
            </div>
        </div>
    </div>
</section>


<!-- Findings -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h1 class="title is-3 has-text-centered">Findings</h1>
            <p>
                We perform experiments with a set of baseline assessors based on various text embeddings approaches and
                41 LLMs. PredictaBoard includes the <a
                    href="https://github.com/Kinds-of-Intelligence-CFI/PredictaBoard">code</a>
                to train those assessors and the <a
                    href="https://huggingface.co/collections/kvoudouris/predictaboard-67b6042ee09a99a3b0bbebd0">instance-level
                LLM results</a>
                on <a href="https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro">MMLU-Pro</a> and <a
                    href="https://github.com/suzgunmirac/BIG-Bench-Hard">Big-Bench Hard (BBH)</a>.
                This allows researchers to work on improving assessors or LLMs independently.
                A split of MMLU-Pro is used to train assessors and another one to test them; instead, BBH is kept as
                Out-Of-Distribution dataset.
            </p>
        </div>
    </div>
</section>

<!-- Image sections -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <div class="item" style="text-align: center; margin-bottom: 4rem;">
                <h1 class="title is-4 has-text-centered">
                    <b>In-distribution results</b>
                </h1>

                <div style="width: 100%; margin: 0 auto;">
                    {% set leaderboard = leaderboard_ID %}
                    {% include "leaderboard.html" %}
                </div>


                <img src="static/images/ID_combined_heatmaps.svg"
                     alt="In-distribution Predictably Valid Regions and Area Under the Accuracy Rejection Curve"
                     style="width: 50%; object-fit: contain; margin: 0 auto 20px auto;"/>
                <div class="content has-text-justified">
                    <p>
                        The figure above shows the top LLM-assessor pairs for three minimum accuracy thresholds (0.8,
                        0.9, 0.95).
                        At a threshold of 0.8, the top LLM-assessor pairs perform well, as assessors can reliably
                        predict
                        success. However, when the threshold increases to 0.9 or higher, the predictably valid region
                        drops
                        significantly, as assessors face greater difficulty in anticipating failures. The
                        best-performing
                        pairs consistently include LLMs with high average accuracy, which aligns with expectations.
                        Interestingly, the ranking of LLM-assessor pairs is not preserved across different thresholds,
                        highlighting variations in assessor effectiveness. These findings underscore the importance of
                        developing AI systems capable of operating under strict error constraints, particularly in
                        high-risk
                        scenarios. Future research will explore even higher thresholds to further enhance AI safety.
                    </p>
                </div>
            </div>

            <div class="item" style="text-align: center; margin-bottom: 4rem;">
                <h1 class="title is-4 has-text-centered">
                    <b>Out-of-distribution results</b>
                </h1>

                <div style="width: 100%; margin: 0 auto;">
                    {% set leaderboard = leaderboard_OOD %}
                    {% include "leaderboard.html" %}
                </div>


                <img src="static/images/OOD_combined_heatmaps.svg"
                     alt="Out-of-distribution Predictably Valid Regions and Area Under the Accuracy Rejection Curve"
                     style="width: 50%; object-fit: contain; margin: 0 auto 20px auto;"/>

                     <div class="content has-text-justified">
                    <p>
                        The figure above shows the top LLM-assessor pairs for three minimum accuracy thresholds (0.8,
                        0.9,
                        0.95).
                        The lower values with respect to the in-distribution case highlight the difficulty of predicting
                        performance OOD. Additionally, the top pairs differ from the in-distribution ones, suggesting
                        the
                        latter may not have the highest generalisation power.
                    </p>
                </div>
            </div>

            <div class="item" style="text-align: center;">
                <h1 class="title is-4 has-text-centered">
                    <b>Visualisation of some Accuracy-Rejection Curves</b>
                </h1>
                <img src="static/images/experiments_ARC_top_scorer.svg"
                     alt="Visualisation of some Accuracy-Rejection Curves"
                     style="width: 35%; object-fit: contain; margin: 2px auto 2px auto;"/>
                <h2 class="subtitle has-text-justified is-6" style="max-width: 800px; margin: 0 auto;">
                    Comparison of the ARC curves for the different in-distribution assessors of the highest accuracy LLM
                    (<code>OpenAI/GPT-4o-2024-08-06</code>) on MMLU-Pro.
                </h2>
            </div>
        </div>
    </div>
</section>
<!-- End image sections -->

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-11">
                <h2 class="subtitle has-text-justified is-italic">
                    Overall, current LLMs are very poorly predictable, particularly at low error thresholds,
                    which is critical for high-stakes scenarios.
                    PredictaBoard makes predictability the key consideration, stimulating research into more predictable
                    AI systems.
                </h2>
            </div>
        </div>
    </div>
</section>


<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        {% raw %}
        <pre><code>@misc{pacchiardi2025predictaboardbenchmarkingllmscore,
              title={{PredictaBoard}: Benchmarking {LLM} Score Predictability},
              author={Lorenzo Pacchiardi and Konstantinos Voudouris and Ben Slater and Fernando Martínez-Plumed and José Hernández-Orallo and Lexin Zhou and Wout Schellaert},
              year={2025},
              eprint={2502.14445},
              archivePrefix={arXiv},
              primaryClass={cs.CL},
              url={https://arxiv.org/abs/2502.14445},
        }</code></pre>
        {% endraw %}    </div>
</section>
<!--End BibTex citation -->



<section class="section">
    <div class="container is-max-desktop">
        <h2 class="title">Acknowledgements</h2>
        <div class="columns is-centered has-text-centered">
            <div class="column is-11">
                <h2 class="subtitle has-text-left is-6">
                This research project has benefitted from the Microsoft Accelerate Foundation Models Research (AFMR) grant program.
                </h2>
            </div>
        </div>
    </div>
</section>


<footer class="footer py-2">
    <div class="container">
        <div class="columns">
            <div class="column is-8">
                <div class="content is-small has-text-right">
                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>

